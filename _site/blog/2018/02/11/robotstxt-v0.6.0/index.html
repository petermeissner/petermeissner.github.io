<!DOCTYPE html>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta charset="utf-8">
<meta name="author" content="Peter Meissner">
<meta name="description" content="petermeissner: personal blog, stats, tech, and things between and beyond">
<title> Robotstxt Update - v0.6.0 on CRAN › petermeissner</title>
<link rel="canonical" href="https://petermeissner.de/blog/2018/02/11/robotstxt-v0.6.0/">
<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,300italic,400italic" rel="stylesheet">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
<link href="https://petermeissner.de/basic.css" rel="stylesheet">
<link href="https://petermeissner.de/highlight.css" rel="stylesheet">
<link href="https://petermeissner.de/index.css" rel="stylesheet">
<link type="application/atom+xml" rel="alternate" href="/https://petermeissner.de/feed.xml" title="petermeissner" />
<script src="//petermeissner-de.disqus.com/embed.js" async></script>

<header>
  <h1><a href="https://petermeissner.de">petermeissner</a></h1>
  <nav>
    <div><a href="https://petermeissner.de/">Home</a><a href="https://petermeissner.de/about/">About</a><a href="https://petermeissner.de/links/">Links</a><a href="https://petermeissner.de/archive/">Archive</a></div>
    <div><a href="https://twitter.com/marvin_dpr"><i class="fa fa-twitter"></i></a><a href="https://github.com/petermeissner"><i class="fa fa-github"></i></a><a href="mailto:retep.meissner@gmail.com"><i class="fa fa-envelope"></i></a></div>
  </nav>
</header>
<main>
  <article>
    <header>
      <h1><a href="https://petermeissner.de/blog/2018/02/11/robotstxt-v0.6.0/">Robotstxt Update - v0.6.0 on CRAN</a></h1>
      <time datetime="2018-02-11T14:16:01+01:00">February 11, 2018</time>
      <p><tag>
              [ rstats ]
            </tag><tag>
              [ robotstxt ]
            </tag></p>
    </header>
    <div>
<p>I just got the news from the CRAN-team that the robotstxt version update 0.6.0 
was accepted and now is available.</p>

<p>The robotstxt package aims at working with robots.txt files from within R by 
providing a parser as well as a permission checker - and some convenience 
goodies working behind the scenes.</p>

<p>This new version switches the default checking backend from an pure R 
implementation (done by myself) to a C++ implementation (done by <a href="https://github.com/seomoz/rep-cpp">Moz</a> and wrapped by <a href="https://github.com/hrbrmstr/spiderbar">Bob Rudis</a>) that is both executing much faster 
and also much more rigourous in interpreting the the standard (<a href="http://www.robotstxt.org/norobots-rfc.txt">RFC</a>). While it was hard to throw 
away so much of my own work it also is very liberating to now have to 
maintain lesser code and leaving the package with the feeling that it now is 
in a better state (more robust) than before.</p>

<p>Thanks CRAN, thanks Bob, thanks Moz.</p>

    </div>
    
    
    <hr><div id="disqus_thread"></div>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    
  </article>
</main>


<footer>
     <span></span> 
    <a href="https://petermeissner.de/blog/2018/02/04/up-and-running/">Up and Running »</a>
</footer>

